{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66932677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1045 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1046it [00:47, 22.04it/s]                          \n"
     ]
    }
   ],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "import tqdm\n",
    "\n",
    "# Specify the Parquet file paths\n",
    "input_parquet_file_path = 'pairs_df.parquet'\n",
    "output_parquet_file_path = 'pairs_df_with_rows.parquet'\n",
    "\n",
    "# Define chunk size (number of rows to read and modify at a time)\n",
    "chunk_size = 64_000  # Adjust this according to your needs\n",
    "\n",
    "# Open the input Parquet file\n",
    "input_parquet_file = pq.ParquetFile(input_parquet_file_path)\n",
    "\n",
    "# Get the total number of rows\n",
    "total_rows = input_parquet_file.metadata.num_rows\n",
    "\n",
    "arrow_schema = input_parquet_file.schema.to_arrow_schema()\n",
    "\n",
    "print(total_rows)\n",
    "\n",
    "# delete pairs_df_with_rows.parquet if it already exists\n",
    "import os\n",
    "if os.path.exists(output_parquet_file_path):\n",
    "    os.remove(output_parquet_file_path)\n",
    "\n",
    "\n",
    "parquet_file = pq.ParquetFile(input_parquet_file_path)\n",
    "\n",
    "output_writer = None\n",
    "\n",
    "for batch in tqdm.tqdm(parquet_file.iter_batches(chunk_size), total=int(total_rows / chunk_size)):\n",
    "    batch_df = batch.to_pandas()\n",
    "    batch_df['row_id'] = batch_df['census_id'] + '_' + batch_df['deepdao_organization_id']\n",
    "\n",
    "    modified_chunk_table = pa.Table.from_pandas(batch_df)\n",
    "\n",
    "    # Append the modified chunk_table to the output Parquet file\n",
    "    if not output_writer:\n",
    "        # Create or open the output Parquet file\n",
    "        output_writer = pq.ParquetWriter(\n",
    "            output_parquet_file_path,\n",
    "            modified_chunk_table.schema,\n",
    "        )\n",
    "    output_writer.write_table(modified_chunk_table)\n",
    "\n",
    "# Close the output Parquet writer\n",
    "output_writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66932677"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open the output Parquet file\n",
    "output_parquet_file = pq.ParquetFile(output_parquet_file_path)\n",
    "\n",
    "# Get the total number of rows\n",
    "output_parquet_file.metadata.num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyarrow._parquet.ParquetSchema object at 0x1594f13c0>\n",
       "required group field_id=-1 schema {\n",
       "  optional binary field_id=-1 census_id (String);\n",
       "  optional binary field_id=-1 deepdao_organization_id (String);\n",
       "  optional binary field_id=-1 deepdao_name (String);\n",
       "  optional binary field_id=-1 census_name (String);\n",
       "  optional binary field_id=-1 row_id (String);\n",
       "}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parquet_file.schema"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
